<!DOCTYPE  html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"/><title>Chapter 3: Design</title><link href="navigation.css" rel="stylesheet" type="text/css"/><link href="document.css" rel="stylesheet" type="text/css"/></head><body><p class="top_nav"><a href="part14.htm">&lt; Previous</a><span> | </span><a href="../Dissertation%20-%20html.html">Contents</a><span> | </span><a href="part16.htm">Next &gt;</a></p><h2 style="padding-top: 4pt;padding-left: 11pt;text-indent: 0pt;text-align: justify;">Chapter 3: Design</h2><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 11pt;text-indent: 0pt;line-height: 154%;text-align: justify;">Design is one of the essential parts of any engineering process; it helps decide a project&#39;s how, when, where, and why. Within this dissertation, the design pertains to a machine-learning model and the process of producing that model.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 11pt;text-indent: 0pt;line-height: 154%;text-align: justify;">Like most software development, machine learning has a flow to follow to get to the end product. First, data is needed to train the model; in this case, the model is based on images. Initially, for this project, Initially, the plan was to use images that were taken from the inside of a recycling truck as it made its run. A camera system was planned to be attached to the truck, and a remote trigger was going to be used to take the picture when the recycling was emptied into the truck. Using this idea would mean getting ideal data that would mimic what the model would see if deployed in the real world. However, it was not possible after several attempts and significant time trying to get this going. This was the first and largest design decision and change necessary to continue the project.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 11pt;text-indent: 0pt;line-height: 154%;text-align: justify;">A data set called trashnet [43] was found online. These images were different from the ones originally wanted; instead of multiple pieces of rubbish and recycling within a single picture, this had a single item of rubbish or recycling in a single picture. Although this was not originally the wanted images, this would allow the idea to be tested and the results to be examined. However, to test the model against the original idea, a different set of images were used for the testing portion. The testing images were collected by taking a recycling bin and using the content to simulate what would be seen in a real-world case. This meant that the testing images would have multiple items within each image for detection.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 11pt;text-indent: 0pt;line-height: 154%;text-align: justify;">Once the images were all collected, the next stage was to pick a machine-learning technique for the project. After searching for a while and consulting experts such as Dr Peter Reuteman, the conclusion was to use image segmentation. This is the process in which labels are applied to pixels within an image. These annotated images are then run through the machine learning model. Mainly, image segmentation was chosen due to the pixels tracing the shape of the objects, as opposed to creating a bounding box. Although the training images had a single item inside each, the testing images, which mimic real-world use, had multiple different items in each image. Using a simple bounding box did not allow the detection of most objects as many overlaps.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 11pt;text-indent: 0pt;line-height: 154%;text-align: justify;">Image segmentation is a supervised learning technique, which means that all inputs, in this case, the images need to be labelled so that the algorithm understands what it is training. This project utilised</p><p style="padding-top: 4pt;padding-left: 11pt;text-indent: 0pt;line-height: 154%;text-align: justify;">a software called ADAMS [42], which is used to label each image and output the correct format ready for training.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 11pt;text-indent: 0pt;line-height: 154%;text-align: justify;">Training the model is the step where the algorithm is decided and parameters such as how many training epochs are to run. Within this project, there are two different algorithms used. The two algorithms are unet and segnet. Both algorithms use the resnet50 encoder, which helps with the vanishing gradient problem. Unet and Segnet are both popular algorithms that are used for image segmentation.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 11pt;text-indent: 0pt;line-height: 154%;text-align: justify;">After selecting the algorithm, the next step is training the model. For this, a development environment is needed that ensures that the training process is equal across all tests to remove as few outside factors as possible. For this, Docker [39] is utilised. Docker allows the creation of containers separate from the rest of the computer. This allows an environment that is safe from other influences on the computer.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 11pt;text-indent: 0pt;line-height: 154%;text-align: justify;">Docker sets up the environment for training, and next, the actual model and code for training needs to be set up in this environment. For this project, the Keras image segmentation [41] was used. This framework is built on top of TensorFlow [44], a leading library for machine learning. Using the Keras segmentation framework [41], the training process can begin. First, the annotated images were transferred into the docker instance, and then the training started.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 11pt;text-indent: 0pt;line-height: 154%;text-align: justify;">After the model has been trained, it is time for testing. Using the Keras image segmentation framework [41], an evaluation script is provided to gain results, as well as a script that will create the predicted models from the testing data. First, the testing data was run through the model, and the results were recorded, with the following model being loaded and subsequently recorded. After all the results were obtained, the script was used to create a prediction from the test data.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 11pt;text-indent: 0pt;line-height: 154%;text-align: justify;">Finally, after recording the results, the final step of any design is the evaluation step. Here the results are taken, and the reason for them is discussed.</p><p class="nav">&nbsp;&nbsp;</p><p class="nav">&nbsp;</p><p class="nav"><a href="part14.htm">&lt; Previous</a><span> | </span><a href="../Dissertation%20-%20html.html">Contents</a><span> | </span><a href="part16.htm">Next &gt;</a></p><p class="nav">&nbsp;&nbsp;</p></body></html>
